{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8804996332000824753\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/sarth/Downloads/Datasets/sentiment analysis/Twitter_Data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure column names are correct\n",
    "text_column = 'clean_text'  # Update if column name differs\n",
    "category_column = 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Extract text and labels\n",
    "texts = data[text_column].astype(str).tolist()\n",
    "labels = data[category_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Padding\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = pad_sequences(X_train_seq, maxlen=100, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=100, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_train: [-1.  0.  1. nan]\n",
      "Unique values in y_test: [-1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in y_train:\", np.unique(y_train))\n",
    "print(\"Unique values in y_test:\", np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.clip(y_train, 0, 2)  # Ensure values are within [0, 2]\n",
    "y_test = np.clip(y_test, 0, 2)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "y_train = np.nan_to_num(y_train, nan=0).astype(int)\n",
    "y_test = np.nan_to_num(y_test, nan=0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered_y_train: 4\n",
      "Updated y_train: [1 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "y_train = np.array([1, 2, -2147483648, 2, -2147483648, 2])\n",
    "filtered_y_train = y_train[y_train != -2147483648]\n",
    "\n",
    "print(\"Length of filtered_y_train:\", len(filtered_y_train))\n",
    "\n",
    "# Ensure the mode computation works\n",
    "most_frequent_label = mode(filtered_y_train, keepdims=True).mode[0]\n",
    "\n",
    "# Replace invalid labels with the most frequent label\n",
    "y_train = np.where(y_train == -2147483648, most_frequent_label, y_train)\n",
    "\n",
    "print(\"Updated y_train:\", y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=128, input_length=100),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # 3 classes: -1, 0, 1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 64)           49408     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,344,131\n",
      "Trainable params: 1,344,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_padded: (130384, 100)\n",
      "Shape of y_train: (6,)\n",
      "Shape of y_train_one_hot: (6, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train_padded:\", X_train_padded.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_train_one_hot:\", y_train_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch: 130384 samples in X_train, but 6 labels in y_train.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "# Replace invalid values (-2147483648) and NaN in y_train\n",
    "y_train = np.nan_to_num(y_train, nan=-2147483648)\n",
    "filtered_y_train = y_train[y_train != -2147483648]\n",
    "\n",
    "# Determine the most frequent label\n",
    "most_frequent_label = mode(filtered_y_train, keepdims=True).mode[0]\n",
    "\n",
    "# Replace invalid labels with the most frequent label\n",
    "y_train = np.where(y_train == -2147483648, most_frequent_label, y_train)\n",
    "\n",
    "# Check alignment with X_train_padded\n",
    "if len(X_train_padded) != len(y_train):\n",
    "    print(f\"Mismatch: {len(X_train_padded)} samples in X_train, but {len(y_train)} labels in y_train.\")\n",
    "    y_train = np.resize(y_train, len(X_train_padded))  # Resize y_train to match X_train\n",
    "\n",
    "# One-hot encode the labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4075/4075 [==============================] - 582s 141ms/step - loss: 0.4546 - accuracy: 0.8331 - val_loss: 6.2332 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "4075/4075 [==============================] - 455s 112ms/step - loss: 0.4514 - accuracy: 0.8333 - val_loss: 6.7814 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "4075/4075 [==============================] - 465s 114ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 7.5855 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "4075/4075 [==============================] - 653s 160ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 8.7565 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "4075/4075 [==============================] - 861s 211ms/step - loss: 0.4510 - accuracy: 0.8333 - val_loss: 9.8543 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_padded, y_train_one_hot,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_padded, y_test_one_hot)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019/1019 [==============================] - 44s 44ms/step - loss: 9.8543 - accuracy: 0.0000e+00\n",
      "Test Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test_padded, y_test_one_hot)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019/1019 [==============================] - 42s 42ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00   18213.0\n",
      "     Neutral       0.00      0.00      0.00   14383.0\n",
      "    Positive       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00   32596.0\n",
      "   macro avg       0.00      0.00      0.00   32596.0\n",
      "weighted avg       0.00      0.00      0.00   32596.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test_padded)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred_classes, target_names=['Negative', 'Neutral', 'Positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
